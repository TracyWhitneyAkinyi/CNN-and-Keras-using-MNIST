{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6497d051",
   "metadata": {},
   "source": [
    "# Digit recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f52ac3",
   "metadata": {},
   "source": [
    " Developers and scientists are diving into machine learning and deep learning techniques,to make machines more intelligent.Take a practical example,a human being learns how to ride a bicycle by repearting it over and over again, so that she memorizes how to ride a bicycle. The neurons in her brain automatically trigger and they can quickly and automatically how to ride a bicycle if she ois given one. This defines **deep learning** . Deep learning  uses different neural network architectures for different types of problems such as image segmentation,object recognition,object detection and image and sound classification.\n",
    " \n",
    "In this project, we are going to implement a digit recognition using the MNIST dataset.We will be using a type of deep neural netork known as *Convolutional Neural Networks* amd know how to create a Keras-based neural network in TensorFlow that processes the MNIST dataset\n",
    "The MNIST dataset contains 60,000 tarining images of handwritten digits from 0 to 9 and 10,000  testing images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "092e9fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_24 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "6000/6000 [==============================] - 84s 14ms/step - loss: 0.1167 - accuracy: 0.9636\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [[3.3952665e-06 5.0980027e-04 9.0646237e-05 6.4166002e-06 9.9907148e-01\n",
      "  2.2110012e-06 9.0065631e-05 1.6856332e-04 2.9679368e-05 2.7772752e-05]]\n",
      "Result.argmax(): 4\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "#import libraries \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "# a.)\n",
    "#load the MNIST dataset and split between train and test sets representes as a 28*28 matrix\n",
    "(train_images,train_labels),(test_images,test_labels)=tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "\n",
    "#The MNIST dataset has 60,000 training images and 10,000 testing images\n",
    "train_images=train_images.reshape((60000,28,28,1))\n",
    "test_images=test_images.reshape((10000,28,28,1))\n",
    "\n",
    "# b.)\n",
    "#Normalize pixel values from range of 0-255 to 0-1\n",
    "train_images,test_images=train_images/255.0 ,test_images/255.0\n",
    "\n",
    "model=tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(32, (3,3),activation='relu',input_shape=(28,28,1)))\n",
    "model.add(tf.keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(tf.keras.layers.Conv2D(64, (3,3),activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(tf.keras.layers.Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# C.)\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics='accuracy')\n",
    "model.fit(train_images,train_labels,epochs=1,batch_size=10)\n",
    "\n",
    "\n",
    "\n",
    "#predict label of one image\n",
    "test_image=np.expand_dims(test_images[300],axis=0)\n",
    "plt.imshow(test_image.reshape(28,28))\n",
    "plt.show()\n",
    "\n",
    "result=model.predict(test_image)\n",
    "print(\"Result:\",result)\n",
    "print(\"Result.argmax():\",result.argmax())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac638bf6",
   "metadata": {},
   "source": [
    "## Documentation.\n",
    "To clearly understand what is taking place we will have a step by step procedure of the codes\n",
    " * a.) **Preprocessing the data** :\n",
    "  *After initializing the training data and labels, as well as the test data and labels, via the **load_data()** function,the images are reshaped so that they are 28x28 images . The dimension of the training data is therefore(60000,28,28).The CNN model will need one more dimension so we reshape the matrix to shape (60000,28,28,1)*\n",
    "  \n",
    " * b.) **Creating the model**:\n",
    "   *Then the pixel values are rescaled from the range 0-255 (all integers) to the range 0-1 (decimal values) .The next portion uses the Keras Sequential() API to define a Keras-based model called **model**, which contains two pairs of Conv2D and MaxPooling2D layers, followed by the Flatten layer, and then two consecutive Dense layers\n",
    " Generally,CNN models consist of convolutional and pooling layers. The dropout layer is used to deactivate some neurons and while training it reduces overfitting of the model*.\n",
    " \n",
    " * c.) **Train the model**:\n",
    "  *The model is compiled, trained, and evaluated via the compile(),fit(), and evaluate() methods, The model.fit() function in Keras, will start training the model.It takes into account the training data,epochs and batch size.*\n",
    " \n",
    " * d.) **Prediction**:\n",
    "  *The final part successfully predicts the image whose label is 4, which is then displayed via *matplotlib**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89df181b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
